{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5304b8b-f893-4cd5-bc9a-426321ff3efe",
   "metadata": {},
   "source": [
    "## Libraries Used and Their Detailed Explanation\n",
    "\n",
    "### 1. Data Cleaning\n",
    "- **pandas**  \n",
    "  - Purpose: To load datasets, merge multiple CSV files, handle missing values, remove duplicates, rename columns, and perform overall data manipulation.  \n",
    "  - Why: Pandas provides powerful dataframes which make it easy to explore and clean structured tabular data.  \n",
    "  - Example Use: `pd.read_csv()`, `df.dropna()`, `df.duplicated()`.\n",
    "\n",
    "- **numpy**  \n",
    "  - Purpose: For numerical operations and handling arrays efficiently.  \n",
    "  - Why: Many cleaning operations (like filling missing values or numeric calculations) require fast array operations, which numpy provides.  \n",
    "  - Example Use: `np.mean()`, `np.where()`.\n",
    "\n",
    "---\n",
    "### 2. Data Preprocessing\n",
    "- **Encoding Categorical Features:**  \n",
    "  - **Label Encoding** or **One-Hot Encoding** applied to categorical variables to convert them into numeric form suitable for machine learning.  \n",
    "  - Examples: Gender (`Male`/`Female`) → 1/0, Chest Pain type → multiple binary columns (one-hot).  \n",
    "  - Why: Machine learning models cannot handle string labels directly; encoding ensures proper numeric representation.\n",
    "- **Feature Scaling:**  \n",
    "  - **StandardScaler** from `scikit-learn` applied to numerical features to normalize feature magnitudes.  \n",
    "  - Why: Scaling improves convergence for models like Logistic Regression and avoids bias toward features with larger ranges.\n",
    "---\n",
    "\n",
    "\n",
    "### 3. Exploratory Data Analysis (EDA)\n",
    "- **pandas**  \n",
    "  - Purpose: To generate descriptive statistics, summarize data, check datatypes, and analyze distributions.  \n",
    "  - Why: Helps understand dataset structure, identify skewed features, and detect anomalies before modeling.  \n",
    "  - Example Use: `df.describe()`, `df.info()`.\n",
    "\n",
    "- **numpy**  \n",
    "  - Purpose: Used for statistical calculations during EDA.  \n",
    "  - Why: Helps compute aggregates like mean, median, standard deviation quickly for numerical features.  \n",
    "  - Example Use: `np.std()`, `np.percentile()`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Data Visualization \n",
    "- **matplotlib**  \n",
    "  - Purpose: To create basic plots such as histograms, bar charts, scatter plots, and line plots.  \n",
    "  - Why: Helps visually explore distributions, trends, and relationships between features.  \n",
    "  - Example Use: `plt.hist()`, `plt.scatter()`.\n",
    "\n",
    "- **seaborn**  \n",
    "  - Purpose: To create advanced and aesthetically pleasing visualizations like count plots, box plots, and heatmaps.  \n",
    "  - Why: Makes it easier to analyze class imbalance, feature relationships, and correlations visually.  \n",
    "  - Example Use: `sns.countplot()`, `sns.heatmap()`.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Model Building\n",
    "- **scikit-learn (sklearn)**  \n",
    "  - Purpose: To build the machine learning model (Logistic Regression in this project).  \n",
    "  - Why: Provides a simple, consistent interface to implement classification algorithms and preprocessing tools.  \n",
    "  - Example Use: `LogisticRegression()`, `StandardScaler()`.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Model Evaluation\n",
    "- **scikit-learn (sklearn)**  \n",
    "  - Purpose: To evaluate model performance using metrics like accuracy, precision, recall, F1-score, confusion matrix, and ROC–AUC.  \n",
    "  - Why: Provides reliable and widely accepted evaluation metrics for classification tasks.  \n",
    "  - Example Use: `classification_report()`, `confusion_matrix()`, `roc_auc_score()`, `roc_curve()`.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. scikit-learn Modules Used\n",
    "- **train_test_split** – To divide the dataset into training and testing sets (80:20).  \n",
    "- **StandardScaler** – To scale numerical features for models that are sensitive to feature magnitude.  \n",
    "- **LogisticRegression** – To train the classification model predicting heart disease.  \n",
    "- **classification_report** – To calculate precision, recall, F1-score, and support.  \n",
    "- **confusion_matrix** – To evaluate correct and incorrect predictions.  \n",
    "- **roc_auc_score** – To calculate the Area Under the ROC Curve (AUC).  \n",
    "- **roc_curve** – To generate ROC curve for visual evaluation of model performance.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Overall Summary\n",
    "These libraries together form a complete Python data science toolkit:  \n",
    "- **pandas & numpy** → Data handling, cleaning, analysis  \n",
    "- **matplotlib & seaborn** → Visualization and insights  \n",
    "- **scikit-learn** → Model building and evaluation  \n",
    "\n",
    "They were selected because they are **industry-standard, well-documented, and efficient**, making the entire workflow from raw data to model evaluation smooth and reproducible.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
